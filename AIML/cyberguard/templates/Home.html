import os
import re
import json
import heapq
import ipaddress
import requests
from datetime import datetime
from collections import defaultdict
from typing import Dict, List, Any, Optional
from dataclasses import dataclass, field
import concurrent.futures

from flask import Flask, request, jsonify, render_template
from pydantic import BaseModel, Field

app = Flask(__name__)

# Configuration for Local LLM
LOCAL_LLM_URL = "http://localhost:11434/api/generate"  # Ollama default
LOCAL_LLM_MODEL = "llama3.1:8b"  # High-quality 8B model - RECOMMENDED
LOCAL_LLM_TIMEOUT = 60  # Increased timeout for larger model

# Recommended 7B-8B models for better accuracy:
# - "llama3.1:8b" (Meta's latest, excellent for analysis) - RECOMMENDED
# - "llama3:8b" (Stable, proven performance)
# - "mistral:7b" (Very good for technical analysis)
# - "gemma2:9b" (Google's high-quality model)
# - "qwen2.5:7b" (Alibaba's latest, great for reasoning)
# - "llama2:7b" (Stable fallback option)

# Precompiled datetime patterns
DATETIME_FORMATS = [
    '%d/%b/%Y:%H:%M:%S %z',  # With timezone
    '%d/%b/%Y:%H:%M:%S'      # Without timezone
]

@dataclass(slots=True)
class LogEntry:
    timestamp: datetime
    ip_address: str
    method: str
    endpoint: str
    status_code: int
    response_size: int
    user_agent: str
    referer: str
    raw_log: str

@dataclass(slots=True)
class IPAnalysis:
    ip_address: str
    should_block: bool
    confidence_score: float
    reasons: List[str]
    risk_level: str
    analysis_details: Dict[str, Any]

class AnalysisResult(BaseModel):
    should_block: bool = Field(description="Whether the IP should be blocked")
    confidence_score: float = Field(ge=0.0, le=1.0, description="Confidence score between 0 and 1")
    risk_level: str = Field(description="Risk level: low, medium, high, or critical")
    reasons: List[str] = Field(description="List of reasons for the decision")
    analysis_details: Dict[str, Any] = Field(default_factory=dict, description="Additional analysis details")

class LocalLLMClient:
    """Client for interacting with local LLM via Ollama API"""
    
    def __init__(self, url: str = LOCAL_LLM_URL, model: str = LOCAL_LLM_MODEL):
        self.url = url
        self.model = model
        self.timeout = LOCAL_LLM_TIMEOUT
    
    def generate(self, prompt: str, max_tokens: int = 2048) -> str:
        """Generate text using local LLM"""
        try:
            payload = {
                "model": self.model,
                "prompt": prompt,
                "stream": False,
                "options": {
                    "temperature": 0.1,
                    "num_predict": max_tokens,
                    "top_k": 20,
                    "top_p": 0.8,
                    "repeat_penalty": 1.1,
                    "num_ctx": 4096,  # Increased context for better analysis
                    "num_thread": 8   # Use more threads for 7B+ models
                }
            }
            
            response = requests.post(
                self.url,
                json=payload,
                timeout=self.timeout,
                headers={"Content-Type": "application/json"}
            )
            
            if response.status_code == 200:
                result = response.json()
                return result.get("response", "")
            else:
                raise Exception(f"LLM API error: {response.status_code}")
                
        except requests.exceptions.RequestException as e:
            raise Exception(f"Failed to connect to local LLM: {e}")
    
    def is_available(self) -> bool:
        """Check if the local LLM is available"""
        try:
            response = requests.get(
                "http://localhost:11434/api/tags",
                timeout=5
            )
            return response.status_code == 200
        except:
            return False

class LogAnalysisOutputParser:
    def parse(self, text: str) -> Dict[str, Any]:
        try:
            # Try to extract JSON from the response
            json_match = re.search(r'\{.*\}', text, re.DOTALL)
            if json_match:
                parsed_data = json.loads(json_match.group())
                return self._validate_parsed_data(parsed_data)
            return self._fallback_parse(text)
        except Exception:
            return self._fallback_parse(text)
    
    def _validate_parsed_data(self, data: Dict[str, Any]) -> Dict[str, Any]:
        return {
            "should_block": bool(data.get("should_block", False)),
            "confidence_score": max(0.0, min(1.0, float(data.get("confidence_score", 0.5)))),
            "risk_level": data.get("risk_level", "medium").lower(),
            "reasons": data.get("reasons", ["Analysis completed"]),
            "analysis_details": data.get("analysis_details", {})
        }
    
    def _fallback_parse(self, text: str) -> Dict[str, Any]:
        should_block = any(keyword in text.lower() for keyword in 
                          ['block', 'malicious', 'attack', 'threat', 'suspicious', 'yes'])
        
        # Extract confidence from text if mentioned
        confidence_match = re.search(r'confidence[:\s]*(\d+\.?\d*)', text.lower())
        confidence = float(confidence_match.group(1)) / 100 if confidence_match else 0.5
        
        # Extract risk level
        risk_level = "low"
        if any(word in text.lower() for word in ['high', 'critical', 'severe']):
            risk_level = "high"
        elif any(word in text.lower() for word in ['medium', 'moderate']):
            risk_level = "medium"
        
        return {
            "should_block": should_block,
            "confidence_score": min(1.0, max(0.0, confidence)),
            "risk_level": risk_level,
            "reasons": ["AI analysis completed"],
            "analysis_details": {"parsing_method": "fallback_local"}
        }

class LogProcessor:
    def __init__(self):
        # Combined regex pattern for Apache and Nginx
        self.log_pattern = re.compile(
            r'(?P<ip>\d+\.\d+\.\d+\.\d+)\s+-\s+-\s+\[(?P<timestamp>[^\]]+)\]\s+'
            r'"(?P<method>\w+)\s+(?P<endpoint>[^\s?]+)(?:\?[^"]*)?\s+[^"]*"\s+'
            r'(?P<status>\d+)\s+(?P<size>\d+|-)\s+"(?P<referer>[^"]*)"\s+'
            r'"(?P<user_agent>[^"]*)"'
        )
    
    def parse_log_line(self, line: str) -> Optional[LogEntry]:
        line = line.strip()
        if not line:
            return None
            
        match = self.log_pattern.match(line)
        if not match:
            return None
        
        data = match.groupdict()
        
        # Parse timestamp
        timestamp = None
        for fmt in DATETIME_FORMATS:
            try:
                timestamp = datetime.strptime(data['timestamp'], fmt)
                break
            except ValueError:
                continue
        
        if not timestamp:
            return None
        
        # Parse status code and size
        try:
            status_code = int(data['status'])
            response_size = int(data['size']) if data['size'] != '-' else 0
        except ValueError:
            return None
        
        return LogEntry(
            timestamp=timestamp,
            ip_address=data['ip'],
            method=data['method'],
            endpoint=data['endpoint'],
            status_code=status_code,
            response_size=response_size,
            user_agent=data['user_agent'],
            referer=data['referer'],
            raw_log=line
        )
    
    def process_logs(self, log_content: str) -> List[LogEntry]:
        entries = []
        for line in log_content.split('\n'):
            if not line.strip():
                continue
            entry = self.parse_log_line(line)
            if entry:
                entries.append(entry)
        return entries

class IPBehaviorAnalyzer:
    def __init__(self):
        # Precompile all regex patterns
        self.suspicious_patterns = {
            'sql_injection': [re.compile(p, re.IGNORECASE) for p in [
                r'union\s+select', r'drop\s+table', r'or\s+1=1', r'script>', r'<script'
            ]],
            'xss': [re.compile(p, re.IGNORECASE) for p in [
                r'<script', r'javascript:', r'onerror=', r'onload='
            ]],
            'path_traversal': [re.compile(p, re.IGNORECASE) for p in [
                r'\.\./', r'\.\.\\', r'/etc/passwd', r'/windows/system32'
            ]],
            'command_injection': [re.compile(p, re.IGNORECASE) for p in [
                r';rm\s', r';cat\s', r'`cat\s', r'\|cat\s'
            ]],
            'brute_force_paths': [re.compile(p, re.IGNORECASE) for p in [
                r'/admin', r'/wp-admin', r'/phpmyadmin', r'/.env'
            ]]
        }
        
        # Geo cache to avoid repeated lookups
        self.geo_cache: Dict[str, Dict[str, str]] = {}
    
    def analyze_ip_behavior(self, ip_entries: List[LogEntry]) -> Dict[str, Any]:
        if not ip_entries:
            return {}
        
        # Calculate time span efficiently
        timestamps = [e.timestamp for e in ip_entries]
        min_time, max_time = min(timestamps), max(timestamps)
        time_span = (max_time - min_time).total_seconds() / 3600
        
        # Count status codes
        status_counter = defaultdict(int)
        for entry in ip_entries:
            status_counter[entry.status_code] += 1
        
        # Analyze endpoints
        endpoint_counter = defaultdict(int)
        for entry in ip_entries:
            endpoint_counter[entry.endpoint] += 1
        common_endpoints = dict(sorted(endpoint_counter.items(), key=lambda x: x[1], reverse=True)[:10])
        
        # Analyze user agents
        ua_counter = defaultdict(int)
        for entry in ip_entries:
            ua_counter[entry.user_agent] += 1
        common_agents = dict(sorted(ua_counter.items(), key=lambda x: x[1], reverse=True)[:5])
        
        return {
            'total_requests': len(ip_entries),
            'time_span': time_span,
            'request_rate': len(ip_entries) / time_span if time_span > 0 else len(ip_entries),
            'status_codes': dict(status_counter),
            'endpoints': {
                'unique_endpoints': len(endpoint_counter),
                'most_common': common_endpoints,
                'total_requests': len(ip_entries)
            },
            'user_agents': {
                'unique_agents': len(ua_counter),
                'most_common': common_agents
            },
            'suspicious_patterns': self._detect_suspicious_patterns(ip_entries),
            'geographic_info': self._get_basic_geo_info(ip_entries[0].ip_address)
        }
    
    def _detect_suspicious_patterns(self, entries: List[LogEntry]) -> Dict[str, List[str]]:
        detected = defaultdict(list)
        for entry in entries:
            full_request = f"{entry.endpoint} {entry.user_agent}".lower()
            for pattern_type, patterns in self.suspicious_patterns.items():
                for pattern in patterns:
                    if pattern.search(full_request):
                        detected[pattern_type].append(entry.endpoint)
                        break  # Only need one match per pattern type
        return dict(detected)
    
    def _get_basic_geo_info(self, ip: str) -> Dict[str, str]:
        # Check cache first
        if ip in self.geo_cache:
            return self.geo_cache[ip]
        
        try:
            ip_obj = ipaddress.ip_address(ip)
            geo_info = {
                'is_private': str(ip_obj.is_private),
                'is_multicast': str(ip_obj.is_multicast),
                'is_loopback': str(ip_obj.is_loopback)
            }
        except ValueError:
            geo_info = {'is_private': "False", 'is_multicast': "False", 'is_loopback': "False"}
        
        # Cache result
        self.geo_cache[ip] = geo_info
        return geo_info

class LogAnalysisAgent:
    def __init__(self):
        self.llm_client = LocalLLMClient()
        self.processor = LogProcessor()
        self.analyzer = IPBehaviorAnalyzer()
        self.output_parser = LogAnalysisOutputParser()
        
        # Check if local LLM is available
        if not self.llm_client.is_available():
            print("WARNING: Local LLM not available. Using fallback analysis only.")
        else:
            print(f"Local LLM connected successfully: {LOCAL_LLM_MODEL}")
    
    def _create_analysis_prompt(self, ip_address: str, behavior_analysis: str, recent_entries: str) -> str:
        return f"""You are an expert cybersecurity analyst specializing in web server log analysis and threat detection. Your task is to analyze IP behavior patterns and determine blocking recommendations.

ANALYSIS TARGET:
IP Address: {ip_address}

BEHAVIORAL DATA:
{behavior_analysis}

RECENT LOG ENTRIES:
{recent_entries}

ANALYSIS FRAMEWORK:
Evaluate this IP using the following criteria:

1. TRAFFIC VOLUME ANALYSIS:
   - Request rate per hour (>50 suspicious, >200 likely malicious)
   - Burst patterns vs sustained activity
   - Time-based distribution anomalies

2. ERROR PATTERN ANALYSIS:
   - 404 errors: >50 indicates scanning behavior
   - 403 errors: >20 suggests access attempts to restricted resources
   - 401 errors: >10 indicates authentication attacks
   - Error rate percentage of total requests

3. ENDPOINT TARGETING:
   - Admin interface attempts (/admin, /wp-admin, /phpmyadmin)
   - Configuration file access (.env, config.php, web.config)
   - System file access (/etc/passwd, /proc/*, etc.)
   - Database interface targeting

4. ATTACK SIGNATURE DETECTION:
   - SQL injection patterns (UNION SELECT, DROP TABLE, OR 1=1)
   - XSS attempts (<script>, javascript:, onerror=)
   - Path traversal (../, ..\\, directory climbing)
   - Command injection (; rm, `cat`, |curl, etc.)
   - File inclusion attacks (../../../etc/passwd)

5. BEHAVIORAL ANOMALIES:
   - Rapid user-agent switching
   - Non-standard HTTP methods abuse
   - Excessive unique endpoint requests
   - Suspicious referer patterns

6. THREAT INDICATORS:
   - Known attack tool signatures
   - Automated scanner patterns
   - Botnet behavioral markers
   - Vulnerability probe sequences

DECISION CRITERIA:
- BLOCK if confidence ≥ 0.8 AND (request_rate > 200 OR multiple_attack_patterns OR critical_path_access)
- MONITOR if confidence 0.5-0.8 AND suspicious_but_not_definitive
- ALLOW if confidence < 0.5 AND no_clear_threats

You must respond with ONLY a valid JSON object in this exact format:
{{
    "should_block": boolean,
    "confidence_score": float_between_0_and_1,
    "risk_level": "low|medium|high|critical",
    "reasons": ["specific_reason_1", "specific_reason_2"],
    "analysis_details": {{
        "primary_threats": ["threat_category_1", "threat_category_2"],
        "attack_indicators": ["specific_indicator_1", "specific_indicator_2"],
        "behavioral_score": integer_0_to_100,
        "recommendation": "detailed_action_recommendation"
    }}
}}

CRITICAL: Only recommend blocking with high confidence. False positives harm legitimate users."""
    
    def analyze_ip(self, ip_address: str, ip_entries: List[LogEntry]) -> IPAnalysis:
        if not ip_entries:
            return IPAnalysis(
                ip_address=ip_address,
                should_block=False,
                confidence_score=0.0,
                reasons=["No log entries found for this IP"],
                risk_level="unknown",
                analysis_details={}
            )
        
        # Analyze IP behavior
        behavior_analysis = self.analyzer.analyze_ip_behavior(ip_entries)
        
        # Get recent entries efficiently
        recent_entries = heapq.nlargest(10, ip_entries, key=lambda x: x.timestamp)
        recent_entries_text = "\n".join(
            f"{e.timestamp} {e.method} {e.endpoint} {e.status_code}" for e in recent_entries
        )
        
        # Try AI analysis first
        if self.llm_client.is_available():
            try:
                prompt = self._create_analysis_prompt(
                    ip_address, 
                    json.dumps(behavior_analysis, default=str), 
                    recent_entries_text
                )
                
                response = self.llm_client.generate(prompt, max_tokens=1536)  # Increased for better analysis
                result = self.output_parser.parse(response)
                
                return IPAnalysis(
                    ip_address=ip_address,
                    should_block=result.get('should_block', False),
                    confidence_score=result.get('confidence_score', 0.5),
                    reasons=result.get('reasons', []),
                    risk_level=result.get('risk_level', 'medium'),
                    analysis_details=result.get('analysis_details', {})
                )
            except Exception as e:
                print(f"LLM analysis failed for {ip_address}: {e}")
                return self._fallback_analysis(ip_address, behavior_analysis)
        else:
            return self._fallback_analysis(ip_address, behavior_analysis)
    
    def _fallback_analysis(self, ip_address: str, behavior_analysis: Dict) -> IPAnalysis:
        should_block = False
        reasons = []
        risk_level = "low"
        confidence_score = 0.3
        
        request_rate = behavior_analysis.get('request_rate', 0)
        suspicious_patterns = behavior_analysis.get('suspicious_patterns', {})
        status_codes = behavior_analysis.get('status_codes', {})
        
        # High request rate check
        if request_rate > 500:
            should_block = True
            reasons.append("Extremely high request rate detected (>500 req/hour)")
            risk_level = "critical"
            confidence_score = 0.9
        elif request_rate > 100:
            should_block = True
            reasons.append("High request rate detected (>100 req/hour)")
            risk_level = "high"
            confidence_score = 0.8
        
        # Suspicious patterns check
        if len(suspicious_patterns) > 3:
            should_block = True
            reasons.append("Multiple attack patterns detected")
            risk_level = "high"
            confidence_score = max(confidence_score, 0.8)
        elif len(suspicious_patterns) > 1:
            should_block = True
            reasons.append("Attack patterns detected")
            risk_level = "medium"
            confidence_score = max(confidence_score, 0.6)
        
        # Error rate check
        total_requests = behavior_analysis.get('total_requests', 0)
        error_404 = int(status_codes.get('404', 0))
        error_403 = int(status_codes.get('403', 0))
        error_401 = int(status_codes.get('401', 0))
        
        if total_requests > 0:
            error_rate = (error_404 + error_403 + error_401) / total_requests
            if error_rate > 0.8:
                should_block = True
                reasons.append("High error rate - possible scanning")
                risk_level = "high"
                confidence_score = max(confidence_score, 0.7)
        
        # Single endpoint flooding
        endpoints = behavior_analysis.get('endpoints', {})
        if endpoints.get('unique_endpoints', 0) == 1 and total_requests > 50:
            should_block = True
            reasons.append("Single endpoint flooding detected")
            risk_level = "medium"
            confidence_score = max(confidence_score, 0.6)
        
        if not reasons:
            reasons = ["No significant threats detected"]
        
        return IPAnalysis(
            ip_address=ip_address,
            should_block=should_block,
            confidence_score=confidence_score,
            reasons=reasons,
            risk_level=risk_level,
            analysis_details={"analysis_method": "rule_based_fallback", "behavior_data": behavior_analysis}
        )

# Initialize the agent
agent = LogAnalysisAgent()

def analyze_ip_batch(ip_entries_map: Dict[str, List[LogEntry]]) -> List[Dict[str, Any]]:
    """Process IPs in parallel batches"""
    results = []
    with concurrent.futures.ThreadPoolExecutor(max_workers=4) as executor:
        futures = {
            executor.submit(agent.analyze_ip, ip, entries): ip
            for ip, entries in ip_entries_map.items()
        }
        for future in concurrent.futures.as_completed(futures):
            analysis = future.result()
            results.append({
                'ip': analysis.ip_address,
                'should_block': analysis.should_block,
                'confidence_score': analysis.confidence_score,
                'risk_level': analysis.risk_level,
                'reasons': analysis.reasons,
                'analysis_details': analysis.analysis_details
            })
    return results

@app.route('/analyze_logs', methods=['POST'])
def analyze_logs():
    try:
        data = request.json
        if not data or 'logs' not in data:
            return jsonify({'error': 'No logs provided'}), 400
        
        log_content = data['logs']
        log_entries = agent.processor.process_logs(log_content)
        
        if not log_entries:
            return jsonify({'error': 'No valid log entries found'}), 400
        
        # Group entries by IP efficiently
        ip_entries_map = defaultdict(list)
        for entry in log_entries:
            ip_entries_map[entry.ip_address].append(entry)
        
        # Analyze IPs in parallel
        results = analyze_ip_batch(ip_entries_map)
        
        # Sort by risk level and confidence
        risk_order = {'critical': 4, 'high': 3, 'medium': 2, 'low': 1, 'unknown': 0}
        results.sort(key=lambda x: (risk_order.get(x['risk_level'], 0), x['confidence_score']), reverse=True)
        
        blocked_count = sum(1 for r in results if r['should_block'])
        
        return jsonify({
            'status': 'success',
            'total_ips_analyzed': len(results),
            'total_log_entries': len(log_entries),
            'blocked_ips': blocked_count,
            'results': results,
            'llm_status': 'local' if agent.llm_client.is_available() else 'fallback_only',
            'timestamp': datetime.now().isoformat()
        })
    except Exception as e:
        return jsonify({'error': f'Analysis failed: {str(e)}'}), 500

@app.route('/analyze_single_ip', methods=['POST'])
def analyze_single_ip():
    try:
        data = request.json
        if not data or 'ip' not in data or 'logs' not in data:
            return jsonify({'error': 'IP address and logs required'}), 400
        
        ip_address = data['ip']
        log_content = data['logs']
        
        log_entries = agent.processor.process_logs(log_content)
        ip_entries = [entry for entry in log_entries if entry.ip_address == ip_address]
        analysis = agent.analyze_ip(ip_address, ip_entries)
        
        return jsonify({
            'status': 'success',
            'ip': analysis.ip_address,
            'should_block': analysis.should_block,
            'confidence_score': analysis.confidence_score,
            'risk_level': analysis.risk_level,
            'reasons': analysis.reasons,
            'analysis_details': analysis.analysis_details,
            'llm_status': 'local' if agent.llm_client.is_available() else 'fallback_only',
            'timestamp': datetime.now().isoformat()
        })
    except Exception as e:
        return jsonify({'error': f'Analysis failed: {str(e)}'}), 500

@app.route('/llm_status', methods=['GET'])
def llm_status():
    """Check the status of local LLM"""
    is_available = agent.llm_client.is_available()
    return jsonify({
        'local_llm_available': is_available,
        'model': LOCAL_LLM_MODEL,
        'url': LOCAL_LLM_URL,
        'status': 'connected' if is_available else 'offline'
    })

@app.route('/', methods=['GET'])
def home():
    return render_template('Home2.html')

@app.route('/health', methods=['GET'])
def health_check():
    return jsonify({
        'status': 'healthy',
        'service': 'Log Analysis Agent (Local LLM)',
        'llm_available': agent.llm_client.is_available(),
        'model': LOCAL_LLM_MODEL,
        'timestamp': datetime.now().isoformat()
    })

if __name__ == '__main__':
    print("Starting Log Analysis Agent with Local LLM...")
    print(f"Using model: {LOCAL_LLM_MODEL}")
    print(f"LLM URL: {LOCAL_LLM_URL}")
    
    if agent.llm_client.is_available():
        print("✅ Local LLM is available and ready!")
    else:
        print("⚠️  Local LLM not available. Using rule-based fallback analysis.")
    
    app.run(host='0.0.0.0', port=5000, threaded=True)